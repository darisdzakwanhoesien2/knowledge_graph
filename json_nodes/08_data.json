[
  {
    "entity": "Motion",
    "type": "Concept",
    "domain": "Computer Vision",
    "definition": "Motion in computer vision refers to the apparent displacement of image brightness patterns between consecutive frames in a video sequence, caused by relative movement between the camera and the scene.",
    "description": "It provides critical information about scene dynamics, enabling applications such as tracking, segmentation, and 3D reconstruction. Motion analysis distinguishes between camera motion, object motion, and complex non-rigid deformations.",
    "properties": {
      "Goal": "Estimate and interpret changes in image appearance over time.",
      "Applications": ["Video stabilization", "Object tracking", "Action recognition", "Autonomous navigation"],
      "Methods": ["Optical flow", "Feature tracking", "Block matching", "Differential methods"],
      "Examples": ["Car moving across frames", "Person walking", "Camera panning"]
    },
    "relations": [
      {"type": "analyzed_by", "target": "Optical Flow"},
      {"type": "used_in", "target": "Motion Segmentation"},
      {"type": "enables", "target": "3D Reconstruction"},
      {"type": "related_to", "target": "Temporal Analysis"},
      {"type": "caused_by", "target": "Relative Movement"}
    ],
    "metadata": {
      "created_by": "system",
      "source": "08-motion-00.pdf",
      "created_at": "2025-11-06",
      "version": "1.0"
    }
  },
  {
    "entity": "Optical Flow",
    "type": "Method",
    "domain": "Computer Vision",
    "definition": "Optical flow is the dense 2D vector field representing the apparent motion of brightness patterns between two consecutive image frames, assigning a displacement vector to each pixel.",
    "description": "It models local image changes under the brightness constancy assumption and is used to estimate scene motion, segment moving objects, and support higher-level video analysis.",
    "properties": {
      "Goal": "Compute per-pixel motion vectors between image pairs.",
      "Applications": ["Motion compensation", "Video compression", "Robot navigation", "Medical imaging"],
      "Methods": ["Lucas-Kanade (sparse)", "Horn-Schunck (dense)", "Farneback", "Deep learning-based flow"],
      "Examples": ["Flow field around a moving car", "Expansion flow from camera zoom"]
    },
    "relations": [
      {"type": "is_a", "target": "Motion Estimation"},
      {"type": "assumes", "target": "Brightness Constancy"},
      {"type": "used_in", "target": "Motion Segmentation"},
      {"type": "extended_by", "target": "Deep Optical Flow"},
      {"type": "contrasts_with", "target": "Feature Tracking"}
    ],
    "metadata": {
      "created_by": "system",
      "source": "08-motion-00.pdf",
      "created_at": "2025-11-06",
      "version": "1.0"
    }
  },
  {
    "entity": "Brightness Constancy Assumption",
    "type": "Concept",
    "domain": "Computer Vision",
    "definition": "The brightness constancy assumption states that the intensity of a moving point remains constant between consecutive frames, i.e., I(x, t) = I(x + d, t + 1), where d is the displacement.",
    "description": "It is the foundational constraint in differential optical flow methods, enabling the formulation of the optical flow constraint equation from spatiotemporal image gradients.",
    "properties": {
      "Goal": "Link pixel intensity across time for motion estimation.",
      "Applications": ["Optical flow computation", "Motion detection", "Tracking"],
      "Methods": ["Gradient-based flow", "Aperture problem solving"],
      "Examples": ["Valid for Lambertian surfaces under constant illumination"]
    },
    "relations": [
      {"type": "core_of", "target": "Differential Optical Flow"},
      {"type": "violated_by", "target": "Specular Highlights"},
      {"type": "violated_by", "target": "Occlusion"},
      {"type": "complemented_by", "target": "Smoothness Constraint"}
    ],
    "metadata": {
      "created_by": "system",
      "source": "08-motion-00.pdf",
      "created_at": "2025-11-06",
      "version": "1.0"
    }
  },
  {
    "entity": "Aperture Problem",
    "type": "Concept",
    "domain": "Computer Vision",
    "definition": "The aperture problem arises when observing motion through a local window: only the motion component perpendicular to an edge can be measured, leaving the parallel component ambiguous.",
    "description": "It explains why local motion measurements are underconstrained and requires integration over larger regions or use of corner features to resolve full 2D motion.",
    "properties": {
      "Goal": "N/A",
      "Applications": ["Explains limitations of local flow", "Justifies global methods"],
      "Methods": ["N/A"],
      "Examples": ["Straight edge moving sideways â€” only normal flow detectable"]
    },
    "relations": [
      {"type": "limitation_of", "target": "Local Motion Estimation"},
      {"type": "solved_by", "target": "Global Optimization"},
      {"type": "solved_by", "target": "Corner Features"},
      {"type": "related_to", "target": "Optical Flow Constraint"}
    ],
    "metadata": {
      "created_by": "system",
      "source": "08-motion-00.pdf",
      "created_at": "2025-11-06",
      "version": "1.0"
    }
  },
  {
    "entity": "Lucas-Kanade Method",
    "type": "Method",
    "domain": "Computer Vision",
    "definition": "The Lucas-Kanade method is a sparse, differential technique for optical flow estimation that assumes local motion constancy within small spatial neighborhoods and solves for motion using weighted least squares.",
    "description": "It is efficient and robust when applied to textured regions or tracked features, commonly used in real-time tracking and sparse flow applications.",
    "properties": {
      "Goal": "Estimate local motion at feature points with sub-pixel accuracy.",
      "Applications": ["Feature tracking", "Visual odometry", "Augmented reality"],
      "Methods": ["Local window analysis", "Weighted least squares", "Pyramidal refinement"],
      "Examples": ["Tracking facial landmarks", "Corner point tracking in video"]
    },
    "relations": [
      {"type": "is_a", "target": "Sparse Optical Flow"},
      {"type": "assumes", "target": "Local Smoothness"},
      {"type": "uses", "target": "Image Gradient"},
      {"type": "robust_to", "target": "Small Motions"},
      {"type": "extended_by", "target": "Pyramidal Lucas-Kanade"}
    ],
    "metadata": {
      "created_by": "system",
      "source": "08-motion-00.pdf",
      "created_at": "2025-11-06",
      "version": "1.0"
    }
  },
  {
    "entity": "Horn-Schunck Method",
    "type": "Method",
    "domain": "Computer Vision",
    "definition": "The Horn-Schunck method is a dense optical flow algorithm that minimizes a global energy functional combining the brightness constancy error and a smoothness term across the entire image.",
    "description": "It produces smooth flow fields by enforcing spatial coherence, making it suitable for dense motion estimation even in textureless regions.",
    "properties": {
      "Goal": "Compute smooth, dense optical flow over the full image.",
      "Applications": ["Motion segmentation", "Video editing", "Fluid flow visualization"],
      "Methods": ["Variational optimization", "Euler-Lagrange equations", "Iterative solvers"],
      "Examples": ["Global flow in translating scenes", "Dense flow in medical ultrasound"]
    },
    "relations": [
      {"type": "is_a", "target": "Dense Optical Flow"},
      {"type": "uses", "target": "Global Smoothness"},
      {"type": "complements", "target": "Lucas-Kanade Method"},
      {"type": "foundation_for", "target": "Variational Flow Methods"}
    ],
    "metadata": {
      "created_by": "system",
      "source": "08-motion-00.pdf",
      "created_at": "2025-11-06",
      "version": "1.0"
    }
  },
  {
    "entity": "Motion Segmentation",
    "type": "Method",
    "domain": "Computer Vision",
    "definition": "Motion segmentation is the process of partitioning a video into regions corresponding to independently moving objects based on their motion patterns.",
    "description": "It leverages optical flow or feature trajectories to group pixels with coherent motion, enabling object-level video analysis.",
    "properties": {
      "Goal": "Separate independently moving objects in dynamic scenes.",
      "Applications": ["Video surveillance", "Autonomous driving", "Action analysis"],
      "Methods": ["Flow clustering", "Layered motion models", "Graph cuts"],
      "Examples": ["Separating pedestrian from background", "Isolating multiple cars"]
    },
    "relations": [
      {"type": "uses", "target": "Optical Flow"},
      {"type": "enables", "target": "Object Tracking"},
      {"type": "part_of", "target": "Video Analysis"},
      {"type": "related_to", "target": "Layered Representation"}
    ],
    "metadata": {
      "created_by": "system",
      "source": "08-motion-00.pdf",
      "created_at": "2025-11-06",
      "version": "1.0"
    }
  },
  {
    "entity": "Feature Tracking",
    "type": "Method",
    "domain": "Computer Vision",
    "definition": "Feature tracking involves detecting distinctive points in one frame and finding their corresponding locations in subsequent frames using local search and similarity metrics.",
    "description": "It is a sparse motion representation widely used in real-time systems due to low computational cost and robustness when features are well-distributed.",
    "properties": {
      "Goal": "Maintain persistent point correspondences across video frames.",
      "Applications": ["SLAM", "Structure from Motion", "Camera pose estimation"],
      "Methods": ["KLT tracker", "Descriptor matching", "Sub-pixel refinement"],
      "Examples": ["Tracking Harris corners over time", "Sparse trajectory bundles"]
    },
    "relations": [
      {"type": "alternative_to", "target": "Dense Optical Flow"},
      {"type": "uses", "target": "Local Features"},
      {"type": "input_to", "target": "Structure from Motion"},
      {"type": "implemented_as", "target": "KLT Tracker"}
    ],
    "metadata": {
      "created_by": "system",
      "source": "08-motion-00.pdf",
      "created_at": "2025-11-06",
      "version": "1.0"
    }
  }
]