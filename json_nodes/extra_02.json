[{
  "entity": "Conjugate Gradient Method",
  "type": "Algorithm",
  "domain": "Numerical Linear Algebra",
  "definition": "An iterative Krylov method for solving symmetric positive definite (SPD) linear systems Ax = b by minimizing the A-norm of the error over expanding Krylov subspaces.",
  "description": "CG constructs a sequence of search directions that are A-conjugate, guaranteeing error minimization properties and finite termination in exact arithmetic. It is widely used in PDE solvers, scientific computing, and large sparse systems where direct methods are too expensive.",
  "properties": {
    "Goal": "Solve SPD systems efficiently without forming factorizations.",
    "Applications": ["Elliptic PDEs", "Finite element methods", "Large sparse linear systems", "Optimization"],
    "Methods": ["Krylov subspace iteration", "A-orthogonalization", "Residual minimization"],
    "Examples": ["Solving Poisson equation discretizations", "CG applied to tridiagonal SPD matrices"]
  },
  "relations": [
    {"type": "uses", "target": "Krylov Subspace"},
    {"type": "variant_of", "target": "Krylov Subspace Methods"},
    {"type": "has_variant", "target": "Preconditioned Conjugate Gradient"},
    {"type": "requires", "target": "Symmetric Positive Definite Matrices"}
  ],
  "metadata": {
    "created_by": "system",
    "source": "lecture_notes_krylov_methods.pdf",
    "created_at": "2025-11-18",
    "version": "1.0",
    "synonyms": ["Conjugate Gradient", "CG"]
  }
},
{
  "entity": "Preconditioned Conjugate Gradient",
  "type": "Algorithm",
  "domain": "Numerical Linear Algebra",
  "definition": "A variant of the Conjugate Gradient method that applies a preconditioner M to cluster eigenvalues of A and accelerate convergence.",
  "description": "PCG solves M^{-1}Ax = M^{-1}b using CG on the transformed system. Proper preconditioning reduces iteration count and improves numerical stability.",
  "properties": {
    "Goal": "Improve convergence of CG via spectral conditioning.",
    "Applications": ["PDE solvers", "Large-scale sparse systems", "Domain decomposition"],
    "Methods": ["Left/right preconditioning", "Incomplete factorizations", "Spectral clustering"],
    "Examples": ["IC(0) preconditioning", "AMG-preconditioned CG"]
  },
  "relations": [
    {"type": "extends", "target": "Conjugate Gradient Method"},
    {"type": "uses", "target": "Preconditioning"},
    {"type": "uses", "target": "Krylov Subspace"},
    {"type": "related_to", "target": "Incomplete LU Factorization"}
  ],
  "metadata": {
    "created_by": "system",
    "source": "lecture_notes_krylov_methods.pdf",
    "created_at": "2025-11-18",
    "version": "1.0",
    "synonyms": ["PCG"]
  }
},
{
  "entity": "Krylov Subspace",
  "type": "Concept",
  "domain": "Numerical Linear Algebra",
  "definition": "A subspace K_k(A, r0) = span{r0, Ar0, A²r0, …, A^{k−1}r0} generated by repeated multiplication of the initial residual by A.",
  "description": "Krylov subspaces serve as the foundation for modern iterative methods for linear systems and eigenvalue problems. They enable low-memory, matrix-free solvers for very large sparse matrices.",
  "properties": {
    "Goal": "Approximate solutions by projecting errors onto structured subspaces.",
    "Applications": ["CG", "GMRES", "Lanczos", "Arnoldi", "Eigenvalue solvers"],
    "Methods": ["Polynomial approximation", "Orthogonalization", "Subspace expansion"],
    "Examples": ["Arnoldi basis", "Lanczos basis"]
  },
  "relations": [
    {"type": "foundation_for", "target": "Krylov Subspace Methods"},
    {"type": "used_in", "target": "Conjugate Gradient Method"},
    {"type": "used_in", "target": "GMRES"},
    {"type": "related_to", "target": "Polynomial Approximation"}
  ],
  "metadata": {
    "created_by": "system",
    "source": "lecture_notes_krylov_methods.pdf",
    "created_at": "2025-11-18",
    "version": "1.0"
  }
},

{
  "entity": "Krylov Subspace Methods",
  "type": "Algorithm Family",
  "domain": "Numerical Linear Algebra",
  "definition": "A class of iterative algorithms that approximate solutions to Ax = b or eigenvalue problems by projecting them onto progressively larger Krylov subspaces.",
  "description": "Includes CG, GMRES, MINRES, BiCG, QMR, and others. These methods rely on polynomial approximations to A and require only matrix-vector products, making them ideal for large sparse systems.",
  "properties": {
    "Goal": "Solve large-scale problems using matrix-free operations.",
    "Applications": ["Sparse linear systems", "Eigenvalue problems", "PDE discretizations"],
    "Methods": ["Arnoldi iteration", "Lanczos iteration", "Restarting", "Preconditioning"],
    "Examples": ["GMRES", "CG", "MINRES", "BiCGSTAB"]
  },
  "relations": [
    {"type": "generalization_of", "target": "Conjugate Gradient Method"},
    {"type": "generalization_of", "target": "GMRES"},
    {"type": "built_on", "target": "Krylov Subspace"}
  ],
  "metadata": {
    "created_by": "system",
    "source": "lecture_notes_krylov_methods.pdf",
    "created_at": "2025-11-18",
    "version": "1.0"
  }
},
{
  "entity": "Matrix Factorization",
  "type": "Concept",
  "domain": "Numerical Linear Algebra",
  "definition": "The process of decomposing a matrix into a product of structured factors such as triangular, orthogonal, or diagonal matrices.",
  "description": "Matrix factorizations enable efficient solving of linear systems, eigenvalue problems, and optimization tasks. Examples include LU, QR, Cholesky, Schur, and SVD.",
  "properties": {
    "Goal": "Reduce computational complexity by decomposing matrices into simpler components.",
    "Applications": ["Solving Ax = b", "Eigenvalue algorithms", "Least-squares problems", "Preconditioning"],
    "Methods": ["Pivoting", "Orthogonal transformations", "Triangularization"],
    "Examples": ["LU", "QR", "SVD", "Cholesky", "Schur"]
  },
  "relations": [
    {"type": "includes", "target": "LU Factorization"},
    {"type": "includes", "target": "QR Factorization"},
    {"type": "includes", "target": "Cholesky Factorization"},
    {"type": "includes", "target": "Singular Value Decomposition"},
    {"type": "includes", "target": "Schur Decomposition"}
  ],
  "metadata": {
    "created_by": "system",
    "source": "lecture_notes_factorizations.pdf",
    "created_at": "2025-11-18",
    "version": "1.0",
    "synonyms": ["Matrix Factoring", "Direct Factorization"]
  }
},
{
  "entity": "Incomplete LU Factorization",
  "type": "Method",
  "domain": "Numerical Linear Algebra",
  "definition": "An approximate LU factorization where fill-in is restricted to preserve sparsity, producing L̂ and Ũ such that A ≈ L̂Ũ.",
  "description": "ILU is widely used as a preconditioner in iterative methods, particularly PCG and GMRES. Variants include ILU(0), ILUT, and ILU(k).",
  "properties": {
    "Goal": "Generate effective sparse preconditioners.",
    "Applications": ["PCG", "GMRES", "Iterative solvers for PDEs"],
    "Methods": ["Zero fill-in", "Drop tolerance", "Level-of-fill"],
    "Examples": ["ILU(0) for 5-point Laplacian", "ILUT for sparse CFD matrices"]
  },
  "relations": [
    {"type": "approximation_of", "target": "LU Factorization"},
    {"type": "used_in", "target": "Preconditioned Conjugate Gradient"},
    {"type": "used_in", "target": "GMRES"},
    {"type": "related_to", "target": "Sparsity Structure"}
  ],
  "metadata": {
    "created_by": "system",
    "source": "lecture_notes_factorizations.pdf",
    "created_at": "2025-11-18",
    "version": "1.0",
    "synonyms": ["Incomplete LU"]
  }
},
{
  "entity": "Spectrum Λ(A)",
  "type": "Concept",
  "domain": "Operator Theory / Linear Algebra",
  "definition": "The set of eigenvalues of a matrix A, denoted Λ(A), consisting of all λ such that det(A − λI) = 0.",
  "description": "The spectrum characterizes fundamental properties such as stability, conditioning, and convergence behavior of iterative methods. It is central in spectral radius analysis and polynomial approximation.",
  "properties": {
    "Goal": "Describe intrinsic behavior of linear operators.",
    "Applications": ["Eigenvalue problems", "Stability analysis", "Iterative method convergence", "Spectral decomposition"],
    "Methods": ["Characteristic polynomial", "Schur decomposition", "Jordan form"],
    "Examples": ["Spectrum of a diagonal matrix", "Spectrum of SPD matrices (real, positive)"]
  },
  "relations": [
    {"type": "used_in", "target": "Spectral Radius"},
    {"type": "used_in", "target": "Gershgorin Circle Theorem"},
    {"type": "computed_by", "target": "Schur Decomposition"}
  ],
  "metadata": {
    "created_by": "system",
    "source": "lecture_notes_eigenvalues.pdf",
    "created_at": "2025-11-18",
    "version": "1.0",
    "synonyms": ["Spectrum", "Λ(A)", "Eigenvalue Spectrum"]
  }
},
{
  "entity": "Projection Operator",
  "type": "Concept",
  "domain": "Linear Algebra",
  "definition": "A linear operator P satisfying P² = P, mapping a vector space onto a subspace while acting as identity on that subspace.",
  "description": "Projections decompose vector spaces into direct sums of a target subspace and its complement. They play central roles in numerical methods, approximations, and matrix factorizations.",
  "properties": {
    "Goal": "Reduce dimensionality or isolate components in subspaces.",
    "Applications": ["Least-squares problems", "Krylov methods", "Iterative solvers", "Sylvester equation"],
    "Methods": ["Orthogonal projection", "Oblique projection"],
    "Examples": ["Hermitian projection using PA = (A + A*)/2", "Diagonal projection onto coordinate subspaces"]
  },
  "relations": [
    {"type": "has_property", "target": "Idempotency"},
    {"type": "includes", "target": "Orthogonal Projection"},
    {"type": "includes", "target": "Oblique Projection"},
    {"type": "used_in", "target": "Matrix Subspace"},
    {"type": "used_in", "target": "Factorization Algorithms"}
  ],
  "metadata": {
    "created_by": "system",
    "source": "lecture_notes_projection.pdf",
    "created_at": "2025-11-18",
    "version": "1.0"
  }
}]